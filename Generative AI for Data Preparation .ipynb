{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "def6c2b16be03b8590d636aa576bdaff4206d1ae9e8a5ace4be932c0f896e5bb"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")\nfile_name  = \"dataset.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\nimport pandas as pd\n\n# Path to the CSV file\nfile_path = \"dataset.csv\"\n\n# Read the CSV into a DataFrame (first row treated as headers by default)\ndf = pd.read_csv(file_path)\n\n# Identify columns that contain any missing values\ncols_with_missing = df.columns[df.isna().any()].tolist()\n\n# Output the list of columns with missing values\nprint(\"Columns with missing values:\", cols_with_missing)\n\n# Optional: display missing value counts per column\nmissing_counts = df.isna().sum()\nprint(\"Missing values per column:\")\nprint(missing_counts)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Columns with missing values: ['Screen_Size_cm', 'Weight_kg']\nMissing values per column:\nUnnamed: 0        0\nManufacturer      0\nCategory          0\nScreen            0\nGPU               0\nOS                0\nCPU_core          0\nScreen_Size_cm    4\nCPU_frequency     0\nRAM_GB            0\nStorage_GB_SSD    0\nWeight_kg         5\nPrice             0\ndtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "\n\nimport pandas as pd\n\n# df is the existing DataFrame\n# 1) Replace missing values in the categorical column with its most frequent value\nscreen_size_mode = df['Screen_Size_cm'].mode().iloc[0]\n\n# 2) Replace missing values in the continuous column with its mean value\nweight_kg_mean = df['Weight_kg'].mean()\n\n# Apply the replacements\ndf = df.fillna({\n    'Screen_Size_cm': screen_size_mode,\n    'Weight_kg': weight_kg_mean\n})",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "df['Screen_Size_cm'] = df['Screen_Size_cm'].astype(float)\ndf['Weight_kg'] = df['Weight_kg'].astype(float)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "# Convert Screen_Size_cm (cm) to Screen_Size_inch and rename the column\n# Create a new column with inches and drop the original centimeter column\ndf['Screen_Size_inch'] = df['Screen_Size_cm'] / 2.54\ndf = df.drop(columns=['Screen_Size_cm'])\n# Convert Weight_kg (kg) to Weight_pounds and rename the column\n# Create a new column with pounds and drop the original kilogram column\ndf['Weight_pounds'] = df['Weight_kg'] * 2.2046226218\ndf = df.drop(columns=['Weight_kg'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "\ndf['CPU_frequency'] /= df['CPU_frequency'].max()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "# 1) Convert 'Screen' into indicator variables named 'Screen_<value>'\ndf1 = pd.get_dummies(df['Screen'], prefix='Screen')\n# 2) Append the indicator variables to the original DataFrame\ndf = df.join(df1)\n# 3) Drop the original 'Screen' column from the DataFrame\ndf.drop(columns=['Screen'], inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright Â© 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}